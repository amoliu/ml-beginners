{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import zipfile\n",
    "import time\n",
    "import shutil\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read events...\n",
      "Read brands...\n",
      "Read train...\n",
      "Read test...\n",
      "('Length of train: ', 74645)\n",
      "('Length of test: ', 112071)\n",
      "Features [3]: ['counts', 'device_model', 'phone_brand']\n",
      "XGBoost params. ETA: 0.1, MAX_DEPTH: 3, SUBSAMPLE: 0.7, COLSAMPLE_BY_TREE: 0.7\n",
      "('Length train:', 52251)\n",
      "('Length valid:', 22394)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 50 rounds.\n",
      "[0]\ttrain-mlogloss:2.475345\teval-mlogloss:2.476001\n",
      "[1]\ttrain-mlogloss:2.467219\teval-mlogloss:2.468193\n",
      "[2]\ttrain-mlogloss:2.459949\teval-mlogloss:2.461354\n",
      "[3]\ttrain-mlogloss:2.453308\teval-mlogloss:2.455170\n",
      "[4]\ttrain-mlogloss:2.447250\teval-mlogloss:2.449607\n",
      "[5]\ttrain-mlogloss:2.441922\teval-mlogloss:2.444834\n",
      "[6]\ttrain-mlogloss:2.437024\teval-mlogloss:2.440494\n",
      "[7]\ttrain-mlogloss:2.432812\teval-mlogloss:2.436625\n",
      "[8]\ttrain-mlogloss:2.428823\teval-mlogloss:2.433110\n",
      "[9]\ttrain-mlogloss:2.425162\teval-mlogloss:2.429942\n",
      "[10]\ttrain-mlogloss:2.421856\teval-mlogloss:2.427002\n",
      "[11]\ttrain-mlogloss:2.418884\teval-mlogloss:2.424351\n",
      "[12]\ttrain-mlogloss:2.416175\teval-mlogloss:2.421972\n",
      "[13]\ttrain-mlogloss:2.413577\teval-mlogloss:2.419811\n",
      "[14]\ttrain-mlogloss:2.411444\teval-mlogloss:2.418006\n",
      "[15]\ttrain-mlogloss:2.409331\teval-mlogloss:2.416239\n",
      "[16]\ttrain-mlogloss:2.407467\teval-mlogloss:2.414751\n",
      "[17]\ttrain-mlogloss:2.405706\teval-mlogloss:2.413381\n",
      "[18]\ttrain-mlogloss:2.404193\teval-mlogloss:2.412257\n",
      "[19]\ttrain-mlogloss:2.402594\teval-mlogloss:2.411004\n",
      "[20]\ttrain-mlogloss:2.401236\teval-mlogloss:2.409906\n",
      "[21]\ttrain-mlogloss:2.399931\teval-mlogloss:2.408885\n",
      "[22]\ttrain-mlogloss:2.398737\teval-mlogloss:2.408010\n",
      "[23]\ttrain-mlogloss:2.397702\teval-mlogloss:2.407216\n",
      "[24]\ttrain-mlogloss:2.396594\teval-mlogloss:2.406574\n",
      "[25]\ttrain-mlogloss:2.395649\teval-mlogloss:2.405849\n",
      "[26]\ttrain-mlogloss:2.394675\teval-mlogloss:2.405173\n",
      "[27]\ttrain-mlogloss:2.393797\teval-mlogloss:2.404627\n",
      "[28]\ttrain-mlogloss:2.393074\teval-mlogloss:2.404191\n",
      "[29]\ttrain-mlogloss:2.392352\teval-mlogloss:2.403789\n",
      "[30]\ttrain-mlogloss:2.391673\teval-mlogloss:2.403438\n",
      "[31]\ttrain-mlogloss:2.391023\teval-mlogloss:2.402994\n",
      "[32]\ttrain-mlogloss:2.390400\teval-mlogloss:2.402710\n",
      "[33]\ttrain-mlogloss:2.389856\teval-mlogloss:2.402417\n",
      "[34]\ttrain-mlogloss:2.389262\teval-mlogloss:2.402121\n",
      "[35]\ttrain-mlogloss:2.388689\teval-mlogloss:2.401723\n",
      "[36]\ttrain-mlogloss:2.388154\teval-mlogloss:2.401420\n",
      "[37]\ttrain-mlogloss:2.387650\teval-mlogloss:2.401197\n",
      "[38]\ttrain-mlogloss:2.387204\teval-mlogloss:2.400903\n",
      "[39]\ttrain-mlogloss:2.386789\teval-mlogloss:2.400695\n",
      "[40]\ttrain-mlogloss:2.386270\teval-mlogloss:2.400480\n",
      "[41]\ttrain-mlogloss:2.385823\teval-mlogloss:2.400267\n",
      "[42]\ttrain-mlogloss:2.385455\teval-mlogloss:2.400158\n",
      "[43]\ttrain-mlogloss:2.384953\teval-mlogloss:2.400077\n",
      "[44]\ttrain-mlogloss:2.384588\teval-mlogloss:2.399938\n",
      "[45]\ttrain-mlogloss:2.384261\teval-mlogloss:2.399801\n",
      "[46]\ttrain-mlogloss:2.383936\teval-mlogloss:2.399711\n",
      "[47]\ttrain-mlogloss:2.383568\teval-mlogloss:2.399655\n",
      "[48]\ttrain-mlogloss:2.383248\teval-mlogloss:2.399587\n",
      "[49]\ttrain-mlogloss:2.382924\teval-mlogloss:2.399483\n",
      "[50]\ttrain-mlogloss:2.382658\teval-mlogloss:2.399420\n",
      "[51]\ttrain-mlogloss:2.382357\teval-mlogloss:2.399328\n",
      "[52]\ttrain-mlogloss:2.382026\teval-mlogloss:2.399209\n",
      "[53]\ttrain-mlogloss:2.381702\teval-mlogloss:2.399130\n",
      "[54]\ttrain-mlogloss:2.381418\teval-mlogloss:2.399055\n",
      "[55]\ttrain-mlogloss:2.381103\teval-mlogloss:2.398978\n",
      "[56]\ttrain-mlogloss:2.380848\teval-mlogloss:2.398857\n",
      "[57]\ttrain-mlogloss:2.380598\teval-mlogloss:2.398811\n",
      "[58]\ttrain-mlogloss:2.380284\teval-mlogloss:2.398820\n",
      "[59]\ttrain-mlogloss:2.380029\teval-mlogloss:2.398762\n",
      "[60]\ttrain-mlogloss:2.379732\teval-mlogloss:2.398691\n",
      "[61]\ttrain-mlogloss:2.379466\teval-mlogloss:2.398672\n",
      "[62]\ttrain-mlogloss:2.379258\teval-mlogloss:2.398594\n",
      "[63]\ttrain-mlogloss:2.379048\teval-mlogloss:2.398458\n",
      "[64]\ttrain-mlogloss:2.378776\teval-mlogloss:2.398459\n",
      "[65]\ttrain-mlogloss:2.378546\teval-mlogloss:2.398386\n",
      "[66]\ttrain-mlogloss:2.378251\teval-mlogloss:2.398373\n",
      "[67]\ttrain-mlogloss:2.378016\teval-mlogloss:2.398329\n",
      "[68]\ttrain-mlogloss:2.377733\teval-mlogloss:2.398275\n",
      "[69]\ttrain-mlogloss:2.377570\teval-mlogloss:2.398303\n",
      "[70]\ttrain-mlogloss:2.377416\teval-mlogloss:2.398266\n",
      "[71]\ttrain-mlogloss:2.377074\teval-mlogloss:2.398217\n",
      "[72]\ttrain-mlogloss:2.376929\teval-mlogloss:2.398193\n",
      "[73]\ttrain-mlogloss:2.376755\teval-mlogloss:2.398166\n",
      "[74]\ttrain-mlogloss:2.376513\teval-mlogloss:2.398117\n",
      "[75]\ttrain-mlogloss:2.376289\teval-mlogloss:2.397963\n",
      "[76]\ttrain-mlogloss:2.375994\teval-mlogloss:2.397897\n",
      "[77]\ttrain-mlogloss:2.375769\teval-mlogloss:2.397842\n",
      "[78]\ttrain-mlogloss:2.375540\teval-mlogloss:2.397773\n",
      "[79]\ttrain-mlogloss:2.375354\teval-mlogloss:2.397748\n",
      "[80]\ttrain-mlogloss:2.375143\teval-mlogloss:2.397717\n",
      "[81]\ttrain-mlogloss:2.374846\teval-mlogloss:2.397640\n",
      "[82]\ttrain-mlogloss:2.374664\teval-mlogloss:2.397650\n",
      "[83]\ttrain-mlogloss:2.374414\teval-mlogloss:2.397596\n",
      "[84]\ttrain-mlogloss:2.374240\teval-mlogloss:2.397589\n",
      "[85]\ttrain-mlogloss:2.374030\teval-mlogloss:2.397550\n",
      "[86]\ttrain-mlogloss:2.373781\teval-mlogloss:2.397449\n",
      "[87]\ttrain-mlogloss:2.373543\teval-mlogloss:2.397468\n",
      "[88]\ttrain-mlogloss:2.373377\teval-mlogloss:2.397469\n",
      "[89]\ttrain-mlogloss:2.373118\teval-mlogloss:2.397388\n",
      "[90]\ttrain-mlogloss:2.372920\teval-mlogloss:2.397372\n",
      "[91]\ttrain-mlogloss:2.372717\teval-mlogloss:2.397326\n",
      "[92]\ttrain-mlogloss:2.372515\teval-mlogloss:2.397356\n",
      "[93]\ttrain-mlogloss:2.372336\teval-mlogloss:2.397362\n",
      "[94]\ttrain-mlogloss:2.372170\teval-mlogloss:2.397363\n",
      "[95]\ttrain-mlogloss:2.371920\teval-mlogloss:2.397374\n",
      "[96]\ttrain-mlogloss:2.371735\teval-mlogloss:2.397348\n",
      "[97]\ttrain-mlogloss:2.371504\teval-mlogloss:2.397336\n",
      "[98]\ttrain-mlogloss:2.371322\teval-mlogloss:2.397313\n",
      "[99]\ttrain-mlogloss:2.371113\teval-mlogloss:2.397272\n",
      "[100]\ttrain-mlogloss:2.370925\teval-mlogloss:2.397300\n",
      "[101]\ttrain-mlogloss:2.370746\teval-mlogloss:2.397253\n",
      "[102]\ttrain-mlogloss:2.370532\teval-mlogloss:2.397168\n",
      "[103]\ttrain-mlogloss:2.370310\teval-mlogloss:2.397187\n",
      "[104]\ttrain-mlogloss:2.370108\teval-mlogloss:2.397177\n",
      "[105]\ttrain-mlogloss:2.369927\teval-mlogloss:2.397142\n",
      "[106]\ttrain-mlogloss:2.369752\teval-mlogloss:2.397084\n",
      "[107]\ttrain-mlogloss:2.369607\teval-mlogloss:2.397047\n",
      "[108]\ttrain-mlogloss:2.369447\teval-mlogloss:2.397066\n",
      "[109]\ttrain-mlogloss:2.369255\teval-mlogloss:2.397111\n",
      "[110]\ttrain-mlogloss:2.369079\teval-mlogloss:2.397057\n",
      "[111]\ttrain-mlogloss:2.368839\teval-mlogloss:2.397048\n",
      "[112]\ttrain-mlogloss:2.368691\teval-mlogloss:2.397041\n",
      "[113]\ttrain-mlogloss:2.368539\teval-mlogloss:2.397045\n",
      "[114]\ttrain-mlogloss:2.368402\teval-mlogloss:2.397017\n",
      "[115]\ttrain-mlogloss:2.368233\teval-mlogloss:2.397033\n",
      "[116]\ttrain-mlogloss:2.368097\teval-mlogloss:2.396982\n",
      "[117]\ttrain-mlogloss:2.367931\teval-mlogloss:2.397011\n",
      "[118]\ttrain-mlogloss:2.367689\teval-mlogloss:2.396909\n",
      "[119]\ttrain-mlogloss:2.367513\teval-mlogloss:2.396873\n",
      "[120]\ttrain-mlogloss:2.367351\teval-mlogloss:2.396907\n",
      "[121]\ttrain-mlogloss:2.367178\teval-mlogloss:2.396921\n",
      "[122]\ttrain-mlogloss:2.367014\teval-mlogloss:2.396884\n",
      "[123]\ttrain-mlogloss:2.366886\teval-mlogloss:2.396866\n",
      "[124]\ttrain-mlogloss:2.366708\teval-mlogloss:2.396858\n",
      "[125]\ttrain-mlogloss:2.366479\teval-mlogloss:2.396741\n",
      "[126]\ttrain-mlogloss:2.366280\teval-mlogloss:2.396744\n",
      "[127]\ttrain-mlogloss:2.366090\teval-mlogloss:2.396731\n",
      "[128]\ttrain-mlogloss:2.365862\teval-mlogloss:2.396722\n",
      "[129]\ttrain-mlogloss:2.365657\teval-mlogloss:2.396696\n",
      "[130]\ttrain-mlogloss:2.365508\teval-mlogloss:2.396687\n",
      "[131]\ttrain-mlogloss:2.365304\teval-mlogloss:2.396641\n",
      "[132]\ttrain-mlogloss:2.365106\teval-mlogloss:2.396641\n",
      "[133]\ttrain-mlogloss:2.364964\teval-mlogloss:2.396643\n",
      "[134]\ttrain-mlogloss:2.364788\teval-mlogloss:2.396712\n",
      "[135]\ttrain-mlogloss:2.364626\teval-mlogloss:2.396625\n",
      "[136]\ttrain-mlogloss:2.364415\teval-mlogloss:2.396554\n",
      "[137]\ttrain-mlogloss:2.364286\teval-mlogloss:2.396548\n",
      "[138]\ttrain-mlogloss:2.364094\teval-mlogloss:2.396560\n",
      "[139]\ttrain-mlogloss:2.363947\teval-mlogloss:2.396543\n",
      "[140]\ttrain-mlogloss:2.363739\teval-mlogloss:2.396549\n",
      "[141]\ttrain-mlogloss:2.363542\teval-mlogloss:2.396555\n",
      "[142]\ttrain-mlogloss:2.363376\teval-mlogloss:2.396537\n",
      "[143]\ttrain-mlogloss:2.363170\teval-mlogloss:2.396468\n",
      "[144]\ttrain-mlogloss:2.362940\teval-mlogloss:2.396496\n",
      "[145]\ttrain-mlogloss:2.362797\teval-mlogloss:2.396460\n",
      "[146]\ttrain-mlogloss:2.362638\teval-mlogloss:2.396477\n",
      "[147]\ttrain-mlogloss:2.362513\teval-mlogloss:2.396432\n",
      "[148]\ttrain-mlogloss:2.362339\teval-mlogloss:2.396407\n",
      "[149]\ttrain-mlogloss:2.362189\teval-mlogloss:2.396422\n",
      "[150]\ttrain-mlogloss:2.361988\teval-mlogloss:2.396311\n",
      "[151]\ttrain-mlogloss:2.361861\teval-mlogloss:2.396273\n",
      "[152]\ttrain-mlogloss:2.361692\teval-mlogloss:2.396309\n",
      "[153]\ttrain-mlogloss:2.361589\teval-mlogloss:2.396328\n",
      "[154]\ttrain-mlogloss:2.361404\teval-mlogloss:2.396342\n",
      "[155]\ttrain-mlogloss:2.361249\teval-mlogloss:2.396345\n",
      "[156]\ttrain-mlogloss:2.361065\teval-mlogloss:2.396354\n",
      "[157]\ttrain-mlogloss:2.360916\teval-mlogloss:2.396281\n",
      "[158]\ttrain-mlogloss:2.360674\teval-mlogloss:2.396256\n",
      "[159]\ttrain-mlogloss:2.360570\teval-mlogloss:2.396267\n",
      "[160]\ttrain-mlogloss:2.360422\teval-mlogloss:2.396342\n",
      "[161]\ttrain-mlogloss:2.360280\teval-mlogloss:2.396376\n",
      "[162]\ttrain-mlogloss:2.360100\teval-mlogloss:2.396333\n",
      "[163]\ttrain-mlogloss:2.359899\teval-mlogloss:2.396342\n",
      "[164]\ttrain-mlogloss:2.359725\teval-mlogloss:2.396409\n",
      "[165]\ttrain-mlogloss:2.359583\teval-mlogloss:2.396369\n",
      "[166]\ttrain-mlogloss:2.359436\teval-mlogloss:2.396395\n",
      "[167]\ttrain-mlogloss:2.359291\teval-mlogloss:2.396430\n",
      "[168]\ttrain-mlogloss:2.359146\teval-mlogloss:2.396466\n",
      "[169]\ttrain-mlogloss:2.359000\teval-mlogloss:2.396387\n",
      "[170]\ttrain-mlogloss:2.358854\teval-mlogloss:2.396396\n",
      "[171]\ttrain-mlogloss:2.358753\teval-mlogloss:2.396374\n",
      "[172]\ttrain-mlogloss:2.358604\teval-mlogloss:2.396335\n",
      "[173]\ttrain-mlogloss:2.358412\teval-mlogloss:2.396282\n",
      "[174]\ttrain-mlogloss:2.358243\teval-mlogloss:2.396277\n",
      "[175]\ttrain-mlogloss:2.358084\teval-mlogloss:2.396247\n",
      "[176]\ttrain-mlogloss:2.357946\teval-mlogloss:2.396248\n",
      "[177]\ttrain-mlogloss:2.357809\teval-mlogloss:2.396254\n",
      "[178]\ttrain-mlogloss:2.357631\teval-mlogloss:2.396263\n",
      "[179]\ttrain-mlogloss:2.357473\teval-mlogloss:2.396240\n",
      "[180]\ttrain-mlogloss:2.357356\teval-mlogloss:2.396176\n",
      "[181]\ttrain-mlogloss:2.357209\teval-mlogloss:2.396138\n",
      "[182]\ttrain-mlogloss:2.357018\teval-mlogloss:2.396156\n",
      "[183]\ttrain-mlogloss:2.356918\teval-mlogloss:2.396111\n",
      "[184]\ttrain-mlogloss:2.356764\teval-mlogloss:2.396152\n",
      "[185]\ttrain-mlogloss:2.356650\teval-mlogloss:2.396220\n",
      "[186]\ttrain-mlogloss:2.356533\teval-mlogloss:2.396304\n",
      "[187]\ttrain-mlogloss:2.356422\teval-mlogloss:2.396283\n",
      "[188]\ttrain-mlogloss:2.356230\teval-mlogloss:2.396290\n",
      "[189]\ttrain-mlogloss:2.356059\teval-mlogloss:2.396285\n",
      "[190]\ttrain-mlogloss:2.355952\teval-mlogloss:2.396251\n",
      "[191]\ttrain-mlogloss:2.355773\teval-mlogloss:2.396327\n",
      "[192]\ttrain-mlogloss:2.355618\teval-mlogloss:2.396346\n",
      "[193]\ttrain-mlogloss:2.355531\teval-mlogloss:2.396402\n",
      "[194]\ttrain-mlogloss:2.355349\teval-mlogloss:2.396436\n",
      "[195]\ttrain-mlogloss:2.355247\teval-mlogloss:2.396398\n",
      "[196]\ttrain-mlogloss:2.355125\teval-mlogloss:2.396433\n",
      "[197]\ttrain-mlogloss:2.355011\teval-mlogloss:2.396462\n",
      "[198]\ttrain-mlogloss:2.354862\teval-mlogloss:2.396442\n",
      "[199]\ttrain-mlogloss:2.354728\teval-mlogloss:2.396427\n",
      "[200]\ttrain-mlogloss:2.354632\teval-mlogloss:2.396450\n",
      "[201]\ttrain-mlogloss:2.354510\teval-mlogloss:2.396453\n",
      "[202]\ttrain-mlogloss:2.354405\teval-mlogloss:2.396456\n",
      "[203]\ttrain-mlogloss:2.354241\teval-mlogloss:2.396416\n",
      "[204]\ttrain-mlogloss:2.354107\teval-mlogloss:2.396446\n",
      "[205]\ttrain-mlogloss:2.353988\teval-mlogloss:2.396510\n",
      "[206]\ttrain-mlogloss:2.353842\teval-mlogloss:2.396582\n",
      "[207]\ttrain-mlogloss:2.353726\teval-mlogloss:2.396581\n",
      "[208]\ttrain-mlogloss:2.353605\teval-mlogloss:2.396581\n",
      "[209]\ttrain-mlogloss:2.353395\teval-mlogloss:2.396582\n",
      "[210]\ttrain-mlogloss:2.353275\teval-mlogloss:2.396602\n",
      "[211]\ttrain-mlogloss:2.353146\teval-mlogloss:2.396624\n",
      "[212]\ttrain-mlogloss:2.352994\teval-mlogloss:2.396569\n",
      "[213]\ttrain-mlogloss:2.352873\teval-mlogloss:2.396557\n",
      "[214]\ttrain-mlogloss:2.352752\teval-mlogloss:2.396525\n",
      "[215]\ttrain-mlogloss:2.352638\teval-mlogloss:2.396486\n",
      "[216]\ttrain-mlogloss:2.352511\teval-mlogloss:2.396496\n",
      "[217]\ttrain-mlogloss:2.352385\teval-mlogloss:2.396544\n",
      "[218]\ttrain-mlogloss:2.352262\teval-mlogloss:2.396543\n",
      "[219]\ttrain-mlogloss:2.352119\teval-mlogloss:2.396515\n",
      "[220]\ttrain-mlogloss:2.351922\teval-mlogloss:2.396480\n",
      "[221]\ttrain-mlogloss:2.351749\teval-mlogloss:2.396474\n",
      "[222]\ttrain-mlogloss:2.351572\teval-mlogloss:2.396441\n",
      "[223]\ttrain-mlogloss:2.351460\teval-mlogloss:2.396416\n",
      "[224]\ttrain-mlogloss:2.351351\teval-mlogloss:2.396432\n",
      "[225]\ttrain-mlogloss:2.351141\teval-mlogloss:2.396444\n",
      "[226]\ttrain-mlogloss:2.350982\teval-mlogloss:2.396448\n",
      "[227]\ttrain-mlogloss:2.350901\teval-mlogloss:2.396463\n",
      "[228]\ttrain-mlogloss:2.350725\teval-mlogloss:2.396465\n",
      "[229]\ttrain-mlogloss:2.350603\teval-mlogloss:2.396477\n",
      "[230]\ttrain-mlogloss:2.350473\teval-mlogloss:2.396430\n",
      "[231]\ttrain-mlogloss:2.350305\teval-mlogloss:2.396427\n",
      "[232]\ttrain-mlogloss:2.350186\teval-mlogloss:2.396448\n",
      "[233]\ttrain-mlogloss:2.350065\teval-mlogloss:2.396481\n",
      "Stopping. Best iteration:\n",
      "[183]\ttrain-mlogloss:2.356918\teval-mlogloss:2.396111\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "Predict test set...\n",
      "Training time: 0.86 minutes\n",
      "LS: 2.39615\n",
      "('Writing submission: ', 'submission_2.39615001133_2016-07-22-15-08.csv')\n"
     ]
    }
   ],
   "source": [
    "random.seed(2016)\n",
    "\n",
    "def run_xgb(train, test, features, target, random_state=0):\n",
    "    eta = 0.1\n",
    "    max_depth = 3\n",
    "    subsample = 0.7\n",
    "    colsample_bytree = 0.7\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n",
    "    params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": 12,\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"eta\": eta,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state,\n",
    "    }\n",
    "    num_boost_round = 500\n",
    "    early_stopping_rounds = 50\n",
    "    test_size = 0.3\n",
    "\n",
    "    X_train, X_valid = train_test_split(train, test_size=test_size, random_state=random_state)\n",
    "    print('Length train:', len(X_train.index))\n",
    "    print('Length valid:', len(X_valid.index))\n",
    "    y_train = X_train[target]\n",
    "    y_valid = X_valid[target]\n",
    "    dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    check = gbm.predict(xgb.DMatrix(X_valid[features]), ntree_limit=gbm.best_iteration)\n",
    "    score = log_loss(y_valid.tolist(), check)\n",
    "\n",
    "    print(\"Predict test set...\")\n",
    "    test_prediction = gbm.predict(xgb.DMatrix(test[features]), ntree_limit=gbm.best_iteration)\n",
    "\n",
    "    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "    return test_prediction.tolist(), score\n",
    "\n",
    "\n",
    "def create_submission(score, test, prediction):\n",
    "    # Make Submission\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'submission_' + str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    print('Writing submission: ', sub_file)\n",
    "    f = open(sub_file, 'w')\n",
    "    f.write('device_id,F23-,F24-26,F27-28,F29-32,F33-42,F43+,M22-,M23-26,M27-28,M29-31,M32-38,M39+\\n')\n",
    "    total = 0\n",
    "    test_val = test['device_id'].values\n",
    "    for i in range(len(test_val)):\n",
    "        str1 = str(test_val[i])\n",
    "        for j in range(12):\n",
    "            str1 += ',' + str(prediction[i][j])\n",
    "        str1 += '\\n'\n",
    "        total += 1\n",
    "        f.write(str1)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def map_column(table, f):\n",
    "    labels = sorted(table[f].unique())\n",
    "    mappings = dict()\n",
    "    for i in range(len(labels)):\n",
    "        mappings[labels[i]] = i\n",
    "    table = table.replace({f: mappings})\n",
    "    return table\n",
    "\n",
    "\n",
    "def read_train_test():\n",
    "    # Events\n",
    "    print('Read events...')\n",
    "    events = pd.read_csv(\"events.csv\", dtype={'device_id': np.str})\n",
    "    events['counts'] = events.groupby(['device_id'])['event_id'].transform('count')\n",
    "    events_small = events[['device_id', 'counts']].drop_duplicates('device_id', keep='first')\n",
    "\n",
    "    # Phone brand\n",
    "    print('Read brands...')\n",
    "    pbd = pd.read_csv(\"phone_brand_device_model.csv\", dtype={'device_id': np.str})\n",
    "    pbd.drop_duplicates('device_id', keep='first', inplace=True)\n",
    "    pbd = map_column(pbd, 'phone_brand')\n",
    "    pbd = map_column(pbd, 'device_model')\n",
    "\n",
    "    # Train\n",
    "    print('Read train...')\n",
    "    train = pd.read_csv(\"gender_age_train.csv\", dtype={'device_id': np.str})\n",
    "    train = map_column(train, 'group')\n",
    "    train = train.drop(['age'], axis=1)\n",
    "    train = train.drop(['gender'], axis=1)\n",
    "    train = pd.merge(train, pbd, how='left', on='device_id', left_index=True)\n",
    "    train = pd.merge(train, events_small, how='left', on='device_id', left_index=True)\n",
    "    train.fillna(-1, inplace=True)\n",
    "\n",
    "    # Test\n",
    "    print('Read test...')\n",
    "    test = pd.read_csv(\"gender_age_test.csv\", dtype={'device_id': np.str})\n",
    "    test = pd.merge(test, pbd, how='left', on='device_id', left_index=True)\n",
    "    test = pd.merge(test, events_small, how='left', on='device_id', left_index=True)\n",
    "    test.fillna(-1, inplace=True)\n",
    "\n",
    "    # Features\n",
    "    features = list(test.columns.values)\n",
    "    features.remove('device_id')\n",
    "\n",
    "    return train, test, features\n",
    "\n",
    "\n",
    "train, test, features = read_train_test()\n",
    "print('Length of train: ', len(train))\n",
    "print('Length of test: ', len(test))\n",
    "print('Features [{}]: {}'.format(len(features), sorted(features)))\n",
    "test_prediction, score = run_xgb(train, test, features, 'group')\n",
    "print(\"LS: {}\".format(round(score, 5)))\n",
    "create_submission(score, test, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
